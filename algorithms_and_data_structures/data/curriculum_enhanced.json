{
  "modules": [
    {
      "id": "foundations",
      "title": "üèóÔ∏è Foundations",
      "description": "Core concepts and fundamentals",
      "lessons": [
        {
          "id": "big-o",
          "title": "Big O Notation",
          "content": "## Understanding Big O Notation: The Language of Algorithm Efficiency\n\nYou know how when you're looking for a book in your home library, the time it takes depends on how organized it is? That's exactly what Big O notation helps us understand about algorithms - how their performance changes as we scale up the problem size.\n\n### Why This Matters\n\nImagine you're building an app that starts with 100 users, then grows to 1 million. Big O notation tells you whether your app will still work smoothly or grind to a halt. It's the difference between Instagram loading instantly with billions of photos versus taking minutes to show your feed.\n\n### The Core Concept\n\nBig O notation describes the **worst-case scenario** for how long an algorithm takes relative to the input size. Think of it like this: if you're planning a road trip, you'd want to know the worst traffic conditions you might face, not just the best-case Sunday morning drive.\n\n### Common Time Complexities (From Best to Worst)\n\n#### O(1) - Constant Time: The Holy Grail\nLike looking up a word in a dictionary when you know the exact page number. Whether the dictionary has 100 or 100,000 pages, if you know the page number, it takes the same time.\n\n**Real-world example**: Accessing an array element by index\n```python\ndef get_first_element(arr):\n    return arr[0]  # Always takes same time, regardless of array size\n```\n\n#### O(log n) - Logarithmic Time: The Power of Divide and Conquer\nLike finding a word in a dictionary by repeatedly opening to the middle and deciding which half to search. Each decision eliminates half of the remaining pages.\n\n**Real-world example**: Binary search in a sorted phonebook\n```python\ndef binary_search(sorted_arr, target):\n    left, right = 0, len(sorted_arr) - 1\n    \n    while left <= right:\n        mid = (left + right) // 2\n        if sorted_arr[mid] == target:\n            return mid\n        elif sorted_arr[mid] < target:\n            left = mid + 1  # Eliminate left half\n        else:\n            right = mid - 1  # Eliminate right half\n    return -1\n```\n\n#### O(n) - Linear Time: The Sequential Scanner\nLike reading every page of a book to find a specific quote. If the book is twice as long, it takes twice as long.\n\n**Real-world example**: Finding the maximum value in an unsorted list\n```python\ndef find_max(arr):\n    if not arr:\n        return None\n    max_val = arr[0]\n    for val in arr:  # Must check every element\n        if val > max_val:\n            max_val = val\n    return max_val\n```\n\n#### O(n log n) - Linearithmic Time: The Efficient Sorter\nLike organizing a deck of cards using merge sort - divide the deck, sort smaller piles, then merge them back together.\n\n**Real-world example**: Efficient sorting algorithms\n```python\ndef merge_sort(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = merge_sort(arr[:mid])  # Divide\n    right = merge_sort(arr[mid:])  # Divide\n    return merge(left, right)  # Conquer\n```\n\n#### O(n¬≤) - Quadratic Time: The Nested Loop Trap\nLike comparing every person in a room with every other person for a group photo arrangement. With 10 people, that's 100 comparisons; with 100 people, that's 10,000 comparisons!\n\n**Real-world example**: Bubble sort or finding all pairs\n```python\ndef bubble_sort(arr):\n    n = len(arr)\n    for i in range(n):\n        for j in range(n - 1 - i):  # Nested loop = n¬≤\n            if arr[j] > arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n    return arr\n```\n\n#### O(2‚Åø) - Exponential Time: The Combinatorial Explosion\nLike trying every possible combination of pizza toppings. Each new topping doubles the number of possible pizzas.\n\n**Real-world example**: Naive recursive Fibonacci\n```python\ndef fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)  # Branches exponentially\n```\n\n### Space Complexity: The Memory Dimension\n\nBig O also describes memory usage. Sometimes we trade space for speed:\n\n```python\n# O(1) space - uses same variables regardless of input\ndef sum_array(arr):\n    total = 0\n    for num in arr:\n        total += num\n    return total\n\n# O(n) space - creates new array proportional to input\ndef double_array(arr):\n    return [x * 2 for x in arr]\n```\n\n### Practical Rules of Thumb\n\n1. **Drop Constants**: O(2n) becomes O(n) - at scale, the multiplier doesn't change the growth pattern\n2. **Drop Lower Terms**: O(n¬≤ + n) becomes O(n¬≤) - the highest power dominates\n3. **Different Variables**: O(a + b) not O(n) when dealing with two different inputs\n\n### Real-World Impact\n\nHere's what these complexities mean for actual running time with 1 million items:\n- O(1): 1 operation - instant\n- O(log n): ~20 operations - instant\n- O(n): 1 million operations - ~1 second\n- O(n log n): 20 million operations - ~20 seconds\n- O(n¬≤): 1 trillion operations - ~11 days!\n\n### The Key Insight\n\nBig O isn't about precise timing - it's about understanding how algorithms scale. An O(n¬≤) algorithm might be faster than O(n) for small inputs, but will always lose as data grows. Choose your algorithms based on your expected data size!\n\n### Practice Exercises\n\n1. What's the time complexity of searching for a name in an unsorted list?\n2. If an algorithm takes 1 second for 1000 items and 4 seconds for 2000 items, what's likely its complexity?\n3. Why might you choose an O(n¬≤) algorithm over an O(n log n) algorithm?\n\nRemember: The best algorithm depends on your specific use case. A simple O(n¬≤) sort might be perfect for sorting 10 items, while you'd need O(n log n) for a million items.",
          "topics": ["Time Complexity", "Space Complexity", "Growth Rates", "Complexity Analysis", "Best/Average/Worst Case"],
          "practice_problems": 8,
          "estimated_time": 45,
          "difficulty": "beginner",
          "prerequisites": [],
          "code_examples": "# Complete examples showing different complexities\n\n# O(1) - Constant Time Examples\ndef get_item(arr, index):\n    \"\"\"Access array element - always one operation\"\"\"\n    return arr[index]\n\ndef is_empty(arr):\n    \"\"\"Check if array is empty - always one comparison\"\"\"\n    return len(arr) == 0\n\n# O(log n) - Logarithmic Time Examples\ndef binary_search_recursive(arr, target, left=0, right=None):\n    \"\"\"Binary search - eliminates half each time\"\"\"\n    if right is None:\n        right = len(arr) - 1\n    \n    if left > right:\n        return -1\n    \n    mid = (left + right) // 2\n    \n    if arr[mid] == target:\n        return mid\n    elif arr[mid] < target:\n        return binary_search_recursive(arr, target, mid + 1, right)\n    else:\n        return binary_search_recursive(arr, target, left, mid - 1)\n\n# O(n) - Linear Time Examples\ndef find_all_occurrences(arr, target):\n    \"\"\"Find all occurrences - must check every element\"\"\"\n    indices = []\n    for i, val in enumerate(arr):\n        if val == target:\n            indices.append(i)\n    return indices\n\ndef calculate_sum(arr):\n    \"\"\"Sum all elements - visits each once\"\"\"\n    total = 0\n    for num in arr:\n        total += num\n    return total\n\n# O(n¬≤) - Quadratic Time Examples\ndef find_duplicates(arr):\n    \"\"\"Find all duplicate pairs - compares every element with every other\"\"\"\n    duplicates = []\n    for i in range(len(arr)):\n        for j in range(i + 1, len(arr)):\n            if arr[i] == arr[j]:\n                duplicates.append((i, j))\n    return duplicates\n\ndef selection_sort(arr):\n    \"\"\"Selection sort - nested loops through array\"\"\"\n    n = len(arr)\n    for i in range(n):\n        min_idx = i\n        for j in range(i + 1, n):\n            if arr[j] < arr[min_idx]:\n                min_idx = j\n        arr[i], arr[min_idx] = arr[min_idx], arr[i]\n    return arr\n\n# Space Complexity Examples\ndef reverse_in_place(arr):\n    \"\"\"O(1) space - modifies original array\"\"\"\n    left, right = 0, len(arr) - 1\n    while left < right:\n        arr[left], arr[right] = arr[right], arr[left]\n        left += 1\n        right -= 1\n    return arr\n\ndef reverse_with_new_array(arr):\n    \"\"\"O(n) space - creates new array\"\"\"\n    return arr[::-1]"
        },
        {
          "id": "arrays",
          "title": "Arrays & Dynamic Arrays",
          "content": "## Arrays: The Foundation of Data Structures\n\nThink of an array like a row of numbered lockers in a school hallway. Each locker has a number (index), and you can instantly access any locker if you know its number. This simple concept is the bedrock of computer science.\n\n### Why Arrays Matter\n\nArrays are everywhere in programming:\n- Your Instagram feed? An array of posts\n- Your Spotify playlist? An array of songs\n- Game high scores? An array of numbers\n- This very text? An array of characters!\n\n### The Mental Model\n\nImagine a parking lot with numbered spaces:\n```\n[0] [1] [2] [3] [4] [5] [6] [7]\nüöó  üöô  üöï  üöì  üöö  üöê  üèçÔ∏è  üöó\n```\n\nKey properties:\n1. **Fixed positions**: Space #3 is always between #2 and #4\n2. **Direct access**: Go straight to space #5 without checking others\n3. **Continuous memory**: All spaces are next to each other\n\n### How Arrays Work in Memory\n\nWhen you create an array, the computer:\n1. Finds a continuous block of memory\n2. Divides it into equal-sized slots\n3. Remembers the starting address\n\nAccessing element at index i:\n```\nMemory address = Start address + (i √ó element size)\n```\n\nThis formula is why array access is O(1) - it's just arithmetic!\n\n### Static Arrays vs Dynamic Arrays\n\n#### Static Arrays: The Reliable Classic\n```python\n# In languages like C, arrays have fixed size\n# Python doesn't have true static arrays, but we can simulate the concept\nclass StaticArray:\n    def __init__(self, capacity):\n        self.data = [None] * capacity\n        self.capacity = capacity\n        self.size = 0\n    \n    def set(self, index, value):\n        if 0 <= index < self.capacity:\n            self.data[index] = value\n        else:\n            raise IndexError(\"Index out of bounds\")\n    \n    def get(self, index):\n        if 0 <= index < self.capacity:\n            return self.data[index]\n        raise IndexError(\"Index out of bounds\")\n```\n\n**Pros:**\n- Predictable memory usage\n- No surprise allocations\n- Cache-friendly\n\n**Cons:**\n- Size must be known upfront\n- Can waste memory if not fully used\n- Can't grow if needed\n\n#### Dynamic Arrays: The Flexible Powerhouse\n\nPython lists are dynamic arrays that grow as needed:\n\n```python\nclass DynamicArray:\n    def __init__(self):\n        self.capacity = 1\n        self.size = 0\n        self.data = [None] * self.capacity\n    \n    def append(self, value):\n        if self.size == self.capacity:\n            self._resize()  # Magic happens here!\n        self.data[self.size] = value\n        self.size += 1\n    \n    def _resize(self):\n        # Double the capacity\n        self.capacity *= 2\n        new_data = [None] * self.capacity\n        \n        # Copy old elements\n        for i in range(self.size):\n            new_data[i] = self.data[i]\n        \n        self.data = new_data\n```\n\n### The Amortized O(1) Magic\n\nHere's something fascinating: even though resizing takes O(n) time, appending is still considered O(1) amortized. How?\n\nThink of it like buying coffee:\n- Buy one cup daily = $3/day\n- Buy a coffee maker for $300 = $300 once, then $0.50/day\n\nOver time, the coffee maker is cheaper per cup!\n\nSimilarly, with arrays:\n- Most appends: O(1)\n- Occasional resize: O(n)\n- Average over many operations: O(1)\n\n### Common Array Operations and Their Complexities\n\n```python\nclass ArrayOperations:\n    def __init__(self, arr):\n        self.arr = arr\n    \n    # O(1) Operations\n    def access(self, index):\n        \"\"\"Direct access by index\"\"\"\n        return self.arr[index]\n    \n    def update(self, index, value):\n        \"\"\"Update element at index\"\"\"\n        self.arr[index] = value\n    \n    def append(self, value):\n        \"\"\"Add to end (amortized O(1))\"\"\"\n        self.arr.append(value)\n    \n    # O(n) Operations\n    def insert(self, index, value):\n        \"\"\"Insert at specific position - shifts elements\"\"\"\n        self.arr.insert(index, value)\n    \n    def remove(self, value):\n        \"\"\"Remove first occurrence - shifts elements\"\"\"\n        self.arr.remove(value)\n    \n    def find(self, value):\n        \"\"\"Linear search for value\"\"\"\n        for i, v in enumerate(self.arr):\n            if v == value:\n                return i\n        return -1\n```\n\n### Real-World Array Patterns\n\n#### The Two-Pointer Technique\nLike having two workers starting from opposite ends:\n\n```python\ndef reverse_array(arr):\n    \"\"\"Reverse array in-place using two pointers\"\"\"\n    left, right = 0, len(arr) - 1\n    \n    while left < right:\n        # Swap elements\n        arr[left], arr[right] = arr[right], arr[left]\n        # Move pointers toward center\n        left += 1\n        right -= 1\n    \n    return arr\n\ndef is_palindrome(arr):\n    \"\"\"Check if array reads same forwards and backwards\"\"\"\n    left, right = 0, len(arr) - 1\n    \n    while left < right:\n        if arr[left] != arr[right]:\n            return False\n        left += 1\n        right -= 1\n    \n    return True\n```\n\n#### The Sliding Window\nLike a frame moving across a film strip:\n\n```python\ndef max_sum_subarray(arr, k):\n    \"\"\"Find maximum sum of k consecutive elements\"\"\"\n    if len(arr) < k:\n        return None\n    \n    # Sum first window\n    window_sum = sum(arr[:k])\n    max_sum = window_sum\n    \n    # Slide window\n    for i in range(k, len(arr)):\n        # Remove leftmost, add rightmost\n        window_sum = window_sum - arr[i-k] + arr[i]\n        max_sum = max(max_sum, window_sum)\n    \n    return max_sum\n```\n\n### Array Gotchas and Best Practices\n\n#### The Reference Trap\n```python\n# WRONG: Creates references to same list\nmatrix = [[0] * 3] * 3\nmatrix[0][0] = 1\nprint(matrix)  # [[1,0,0], [1,0,0], [1,0,0]] - Oops!\n\n# RIGHT: Creates independent lists\nmatrix = [[0] * 3 for _ in range(3)]\nmatrix[0][0] = 1\nprint(matrix)  # [[1,0,0], [0,0,0], [0,0,0]] - Correct!\n```\n\n#### The Modification During Iteration Trap\n```python\n# WRONG: Modifying while iterating\narr = [1, 2, 3, 4, 5]\nfor i, val in enumerate(arr):\n    if val % 2 == 0:\n        arr.remove(val)  # Dangerous!\n\n# RIGHT: Create new array or iterate backwards\narr = [1, 2, 3, 4, 5]\narr = [val for val in arr if val % 2 != 0]\n```\n\n### When to Use Arrays\n\n**Arrays are perfect when:**\n- You need fast access by index\n- The size is relatively stable\n- You're doing lots of iterations\n- Cache performance matters\n- You need to maintain order\n\n**Consider alternatives when:**\n- Lots of insertions/deletions in middle (use linked list)\n- Need fast lookups by value (use hash table)\n- Size varies dramatically (use linked structures)\n- Need unique elements (use set)\n\n### The Deep Insight\n\nArrays are like the atoms of data structures - simple, fundamental, and incredibly powerful when understood deeply. Master arrays, and you'll understand why they're the building blocks for more complex structures like strings (character arrays), matrices (2D arrays), and even hash tables (arrays + hashing).\n\n### Practice Challenges\n\n1. Implement a circular buffer using an array\n2. Find the missing number in an array of 1 to n\n3. Rotate an array k positions to the right\n4. Merge two sorted arrays in-place\n5. Find the majority element (appears > n/2 times)\n\nRemember: Arrays might seem simple, but they're involved in nearly every algorithm you'll ever write. Master them, and you master the foundation of computer science!",
          "topics": ["Static Arrays", "Dynamic Arrays", "Memory Layout", "Amortized Analysis", "Common Operations", "Array Patterns"],
          "practice_problems": 10,
          "estimated_time": 60,
          "difficulty": "beginner",
          "prerequisites": ["big-o"],
          "code_examples": "# Array implementation showcase\n\nclass ComprehensiveArray:\n    \"\"\"A feature-rich dynamic array implementation\"\"\"\n    \n    def __init__(self, initial_capacity=10):\n        self.capacity = initial_capacity\n        self.size = 0\n        self.data = [None] * self.capacity\n    \n    def __len__(self):\n        return self.size\n    \n    def __getitem__(self, index):\n        if not -self.size <= index < self.size:\n            raise IndexError(\"Index out of range\")\n        if index < 0:\n            index += self.size\n        return self.data[index]\n    \n    def __setitem__(self, index, value):\n        if not -self.size <= index < self.size:\n            raise IndexError(\"Index out of range\")\n        if index < 0:\n            index += self.size\n        self.data[index] = value\n    \n    def append(self, value):\n        \"\"\"Add element to end - O(1) amortized\"\"\"\n        if self.size == self.capacity:\n            self._resize(2 * self.capacity)\n        self.data[self.size] = value\n        self.size += 1\n    \n    def insert(self, index, value):\n        \"\"\"Insert at position - O(n)\"\"\"\n        if not -self.size <= index <= self.size:\n            raise IndexError(\"Index out of range\")\n        if index < 0:\n            index += self.size\n        \n        if self.size == self.capacity:\n            self._resize(2 * self.capacity)\n        \n        # Shift elements right\n        for i in range(self.size, index, -1):\n            self.data[i] = self.data[i-1]\n        \n        self.data[index] = value\n        self.size += 1\n    \n    def remove(self, index):\n        \"\"\"Remove element at index - O(n)\"\"\"\n        if not -self.size <= index < self.size:\n            raise IndexError(\"Index out of range\")\n        if index < 0:\n            index += self.size\n        \n        value = self.data[index]\n        \n        # Shift elements left\n        for i in range(index, self.size - 1):\n            self.data[i] = self.data[i+1]\n        \n        self.size -= 1\n        \n        # Shrink if necessary\n        if self.size <= self.capacity // 4:\n            self._resize(self.capacity // 2)\n        \n        return value\n    \n    def _resize(self, new_capacity):\n        \"\"\"Resize internal array\"\"\"\n        new_data = [None] * new_capacity\n        for i in range(self.size):\n            new_data[i] = self.data[i]\n        self.data = new_data\n        self.capacity = new_capacity\n    \n    def clear(self):\n        \"\"\"Remove all elements\"\"\"\n        self.size = 0\n        self.capacity = 10\n        self.data = [None] * self.capacity\n    \n    def __str__(self):\n        return str([self.data[i] for i in range(self.size)])\n\n# Advanced array algorithms\n\ndef dutch_flag_partition(arr, pivot_index):\n    \"\"\"Three-way partition around a pivot\"\"\"\n    pivot = arr[pivot_index]\n    smaller, equal, larger = 0, 0, len(arr)\n    \n    while equal < larger:\n        if arr[equal] < pivot:\n            arr[smaller], arr[equal] = arr[equal], arr[smaller]\n            smaller += 1\n            equal += 1\n        elif arr[equal] == pivot:\n            equal += 1\n        else:\n            larger -= 1\n            arr[equal], arr[larger] = arr[larger], arr[equal]\n    \n    return arr\n\ndef kadane_algorithm(arr):\n    \"\"\"Find maximum sum subarray - O(n)\"\"\"\n    if not arr:\n        return 0\n    \n    max_current = max_global = arr[0]\n    \n    for i in range(1, len(arr)):\n        max_current = max(arr[i], max_current + arr[i])\n        max_global = max(max_global, max_current)\n    \n    return max_global\n\ndef rotate_array(arr, k):\n    \"\"\"Rotate array k positions to the right\"\"\"\n    if not arr:\n        return arr\n    \n    k = k % len(arr)\n    if k == 0:\n        return arr\n    \n    # Reverse entire array\n    arr.reverse()\n    # Reverse first k elements\n    arr[:k] = reversed(arr[:k])\n    # Reverse remaining elements\n    arr[k:] = reversed(arr[k:])\n    \n    return arr"
        }
      ]
    },
    {
      "id": "searching",
      "title": "üîç Searching Algorithms",
      "description": "Techniques for finding elements efficiently",
      "lessons": [
        {
          "id": "linear-search",
          "title": "Linear Search",
          "content": "## Linear Search: The Straightforward Detective\n\nImagine you've lost your keys somewhere in your house. What do you do? You check every room, every surface, every pocket until you find them. That's linear search - simple, reliable, and sometimes the only option you have.\n\n### Why Linear Search Matters\n\nWhile it might seem too simple to study, linear search is:\n- The only option for unsorted data\n- Often faster than complex algorithms for small datasets\n- The building block for more sophisticated search techniques\n- Used internally by many built-in functions you use daily\n\n### The Mental Model\n\nThink of linear search like:\n1. **Reading a book page by page** to find a specific quote\n2. **Checking every ticket** in a raffle drum for the winner\n3. **Going through your email** one by one to find that important message\n\nThe key characteristic: we examine each element in sequence until we find what we're looking for or run out of elements.\n\n### Basic Implementation\n\n```python\ndef linear_search(arr, target):\n    \"\"\"The classic linear search\"\"\"\n    for i in range(len(arr)):\n        if arr[i] == target:\n            return i  # Found it! Return the index\n    return -1  # Not found\n\n# Pythonic version\ndef linear_search_pythonic(arr, target):\n    \"\"\"Using Python's elegant enumerate\"\"\"\n    for index, value in enumerate(arr):\n        if value == target:\n            return index\n    return -1\n```\n\n### When Linear Search Shines\n\n#### Small Datasets\nFor arrays with fewer than 100 elements, linear search often outperforms binary search because:\n- No sorting overhead\n- Better cache locality\n- Simpler CPU instructions\n\n#### Unsorted Data\nWhen data isn't sorted, linear search is your only option:\n```python\n# Finding a name in an unsorted guest list\nguests = [\"Alice\", \"Charlie\", \"Bob\", \"David\", \"Eve\"]\nposition = linear_search(guests, \"Bob\")  # Returns 2\n```\n\n#### Finding All Occurrences\n```python\ndef find_all_occurrences(arr, target):\n    \"\"\"Find all positions where target appears\"\"\"\n    positions = []\n    for i, value in enumerate(arr):\n        if value == target:\n            positions.append(i)\n    return positions\n\n# Example: Finding all test scores of 100\nscores = [85, 100, 92, 100, 88, 100, 95]\nperfect_scores = find_all_occurrences(scores, 100)  # [1, 3, 5]\n```\n\n### Optimizing Linear Search\n\n#### Early Termination with Sentinel\nPlace the target at the end to eliminate boundary checking:\n\n```python\ndef sentinel_linear_search(arr, target):\n    \"\"\"Optimized with sentinel value\"\"\"\n    n = len(arr)\n    last = arr[n-1]\n    \n    # Place sentinel\n    arr[n-1] = target\n    \n    # Search without boundary check\n    i = 0\n    while arr[i] != target:\n        i += 1\n    \n    # Restore and check\n    arr[n-1] = last\n    \n    if i < n-1 or arr[n-1] == target:\n        return i\n    return -1\n```\n\n#### Searching with Conditions\n```python\ndef linear_search_with_condition(arr, condition):\n    \"\"\"Search for first element meeting a condition\"\"\"\n    for i, value in enumerate(arr):\n        if condition(value):\n            return i\n    return -1\n\n# Example: Find first number greater than 100\nnumbers = [45, 67, 89, 102, 56, 120]\nindex = linear_search_with_condition(numbers, lambda x: x > 100)  # Returns 3\n```\n\n### Advanced Linear Search Patterns\n\n#### Finding Min/Max\n```python\ndef find_min_max(arr):\n    \"\"\"Find both min and max in single pass\"\"\"\n    if not arr:\n        return None, None\n    \n    min_val = max_val = arr[0]\n    \n    for value in arr[1:]:\n        if value < min_val:\n            min_val = value\n        elif value > max_val:\n            max_val = value\n    \n    return min_val, max_val\n```\n\n#### The Two-Pass Pattern\n```python\ndef find_second_largest(arr):\n    \"\"\"Find second largest element\"\"\"\n    if len(arr) < 2:\n        return None\n    \n    # First pass: find maximum\n    max_val = max(arr)\n    \n    # Second pass: find largest that's not max\n    second = float('-inf')\n    for value in arr:\n        if value != max_val and value > second:\n            second = value\n    \n    return second if second != float('-inf') else None\n```\n\n### Real-World Applications\n\n#### Database Table Scans\nWhen a database doesn't have an index on a column, it performs a linear search (table scan):\n```python\nclass SimpleDatabase:\n    def __init__(self):\n        self.records = []\n    \n    def insert(self, record):\n        self.records.append(record)\n    \n    def find_by_field(self, field_name, value):\n        \"\"\"Linear search through records\"\"\"\n        results = []\n        for record in self.records:\n            if record.get(field_name) == value:\n                results.append(record)\n        return results\n```\n\n#### Text Search\n```python\ndef search_in_text(text, keyword):\n    \"\"\"Find all occurrences of keyword in text\"\"\"\n    lines = text.split('\\n')\n    results = []\n    \n    for line_num, line in enumerate(lines, 1):\n        if keyword.lower() in line.lower():\n            results.append((line_num, line))\n    \n    return results\n```\n\n### Performance Analysis\n\n**Time Complexity:**\n- Best case: O(1) - element is first\n- Average case: O(n/2) ‚âà O(n) - element in middle\n- Worst case: O(n) - element is last or not present\n\n**Space Complexity:** O(1) - only uses a few variables\n\n### Linear Search vs Binary Search\n\n```python\nimport time\nimport random\n\ndef performance_comparison(size):\n    \"\"\"Compare linear vs binary search performance\"\"\"\n    arr = list(range(size))\n    target = random.randint(0, size-1)\n    \n    # Linear search\n    start = time.time()\n    linear_search(arr, target)\n    linear_time = time.time() - start\n    \n    # Binary search (on sorted data)\n    start = time.time()\n    binary_search(arr, target)\n    binary_time = time.time() - start\n    \n    print(f\"Array size: {size}\")\n    print(f\"Linear search: {linear_time:.6f} seconds\")\n    print(f\"Binary search: {binary_time:.6f} seconds\")\n    print(f\"Binary is {linear_time/binary_time:.1f}x faster\")\n```\n\n### The Surprising Truth\n\nLinear search often beats binary search when:\n1. **Data size < 100 elements**: Overhead of binary search isn't worth it\n2. **Data is unsorted**: Sorting cost dominates\n3. **Need all occurrences**: Must check everything anyway\n4. **Cache-friendly access**: Sequential memory access is fast\n\n### Practice Exercises\n\n1. Find the first duplicate in an array\n2. Search for a pattern in a 2D matrix\n3. Find the missing number in a sequence\n4. Implement a fuzzy search (partial matches)\n5. Find the peak element in an array\n\n### The Key Insight\n\nLinear search teaches us that the simplest solution is often the right one. Don't overcomplicate things - sometimes checking every element is exactly what you need. Master linear search, and you'll know when to use it and when to reach for something more sophisticated.",
          "topics": ["Basic Implementation", "Optimization Techniques", "Sentinel Search", "Performance Analysis", "Real-world Applications"],
          "practice_problems": 6,
          "estimated_time": 30,
          "difficulty": "beginner",
          "prerequisites": ["arrays"],
          "code_examples": "# Complete linear search implementations\n\n# Basic variations\ndef linear_search_basic(arr, target):\n    \"\"\"Standard linear search\"\"\"\n    for i in range(len(arr)):\n        if arr[i] == target:\n            return i\n    return -1\n\ndef linear_search_recursive(arr, target, index=0):\n    \"\"\"Recursive linear search\"\"\"\n    if index >= len(arr):\n        return -1\n    if arr[index] == target:\n        return index\n    return linear_search_recursive(arr, target, index + 1)\n\n# Advanced patterns\ndef find_first_and_last(arr, target):\n    \"\"\"Find first and last occurrence\"\"\"\n    first = last = -1\n    \n    for i in range(len(arr)):\n        if arr[i] == target:\n            if first == -1:\n                first = i\n            last = i\n    \n    return first, last\n\ndef find_closest_value(arr, target):\n    \"\"\"Find value closest to target\"\"\"\n    if not arr:\n        return None\n    \n    closest = arr[0]\n    min_diff = abs(arr[0] - target)\n    \n    for value in arr[1:]:\n        diff = abs(value - target)\n        if diff < min_diff:\n            min_diff = diff\n            closest = value\n    \n    return closest\n\n# String search\ndef substring_search(text, pattern):\n    \"\"\"Find all occurrences of pattern in text\"\"\"\n    positions = []\n    n, m = len(text), len(pattern)\n    \n    for i in range(n - m + 1):\n        if text[i:i+m] == pattern:\n            positions.append(i)\n    \n    return positions\n\n# 2D array search\ndef search_2d_array(matrix, target):\n    \"\"\"Search in 2D array\"\"\"\n    for i in range(len(matrix)):\n        for j in range(len(matrix[i])):\n            if matrix[i][j] == target:\n                return (i, j)\n    return None\n\n# Custom comparator search\ndef linear_search_custom(arr, target, compare=lambda x, y: x == y):\n    \"\"\"Search with custom comparison function\"\"\"\n    for i, value in enumerate(arr):\n        if compare(value, target):\n            return i\n    return -1\n\n# Example: Case-insensitive string search\nnames = [\"Alice\", \"Bob\", \"Charlie\"]\nindex = linear_search_custom(\n    names, \n    \"bob\", \n    lambda x, y: x.lower() == y.lower()\n)  # Returns 1"
        },
        {
          "id": "binary-search",
          "title": "Binary Search",
          "content": "## Binary Search: The Art of Intelligent Elimination\n\nYou're playing a guessing game where someone thinks of a number between 1 and 1000. After each guess, they tell you \"higher\" or \"lower\". How many guesses do you need? Surprisingly, just 10! That's the power of binary search - each guess eliminates half of the remaining possibilities.\n\n### The \"Aha!\" Moment\n\nBinary search is like finding a word in a dictionary:\n1. Open to the middle\n2. Is your word before or after this page?\n3. Eliminate half the dictionary\n4. Repeat with the remaining half\n\nWith 1,000 pages, you need at most 10 checks. With 1,000,000 pages? Just 20!\n\n### The Mathematical Magic\n\nBinary search showcases the power of logarithms:\n- 1,000 elements ‚Üí 10 comparisons (log‚ÇÇ1000 ‚âà 10)\n- 1,000,000 elements ‚Üí 20 comparisons (log‚ÇÇ1000000 ‚âà 20)\n- 1,000,000,000 elements ‚Üí 30 comparisons!\n\nThis is why Google can search billions of web pages instantly.\n\n### Core Implementation\n\n```python\ndef binary_search_iterative(arr, target):\n    \"\"\"The classic iterative binary search\"\"\"\n    left, right = 0, len(arr) - 1\n    \n    while left <= right:\n        # Find middle (avoiding overflow in other languages)\n        mid = left + (right - left) // 2\n        \n        if arr[mid] == target:\n            return mid  # Found it!\n        elif arr[mid] < target:\n            left = mid + 1  # Target is in right half\n        else:\n            right = mid - 1  # Target is in left half\n    \n    return -1  # Not found\n\ndef binary_search_recursive(arr, target, left=0, right=None):\n    \"\"\"Elegant recursive version\"\"\"\n    if right is None:\n        right = len(arr) - 1\n    \n    if left > right:\n        return -1  # Base case: not found\n    \n    mid = (left + right) // 2\n    \n    if arr[mid] == target:\n        return mid\n    elif arr[mid] < target:\n        return binary_search_recursive(arr, target, mid + 1, right)\n    else:\n        return binary_search_recursive(arr, target, left, mid - 1)\n```\n\n### The Critical Requirement: Sorted Data\n\nBinary search ONLY works on sorted data. This is non-negotiable:\n\n```python\n# This will give wrong results!\nunsorted = [3, 1, 4, 1, 5, 9, 2, 6]\nresult = binary_search_iterative(unsorted, 5)  # Unreliable!\n\n# Always sort first if needed\nsorted_arr = sorted(unsorted)\nresult = binary_search_iterative(sorted_arr, 5)  # Now it works\n```\n\n### Binary Search Variations\n\n#### Finding First/Last Occurrence\n```python\ndef find_first_occurrence(arr, target):\n    \"\"\"Find the first occurrence of target\"\"\"\n    left, right = 0, len(arr) - 1\n    result = -1\n    \n    while left <= right:\n        mid = (left + right) // 2\n        \n        if arr[mid] == target:\n            result = mid\n            right = mid - 1  # Keep searching left\n        elif arr[mid] < target:\n            left = mid + 1\n        else:\n            right = mid - 1\n    \n    return result\n\ndef find_last_occurrence(arr, target):\n    \"\"\"Find the last occurrence of target\"\"\"\n    left, right = 0, len(arr) - 1\n    result = -1\n    \n    while left <= right:\n        mid = (left + right) // 2\n        \n        if arr[mid] == target:\n            result = mid\n            left = mid + 1  # Keep searching right\n        elif arr[mid] < target:\n            left = mid + 1\n        else:\n            right = mid - 1\n    \n    return result\n```\n\n#### Finding Insert Position\n```python\ndef find_insert_position(arr, target):\n    \"\"\"Find where to insert target to maintain sorted order\"\"\"\n    left, right = 0, len(arr)\n    \n    while left < right:\n        mid = (left + right) // 2\n        \n        if arr[mid] < target:\n            left = mid + 1\n        else:\n            right = mid\n    \n    return left\n\n# Example usage\narr = [1, 3, 5, 7, 9]\npos = find_insert_position(arr, 6)  # Returns 3\n# Insert 6 at position 3: [1, 3, 5, 6, 7, 9]\n```\n\n#### Finding Closest Value\n```python\ndef find_closest(arr, target):\n    \"\"\"Find value closest to target\"\"\"\n    if not arr:\n        return None\n    \n    left, right = 0, len(arr) - 1\n    \n    # Edge cases\n    if target <= arr[left]:\n        return arr[left]\n    if target >= arr[right]:\n        return arr[right]\n    \n    while left < right:\n        mid = (left + right) // 2\n        \n        if arr[mid] == target:\n            return arr[mid]\n        elif arr[mid] < target:\n            left = mid + 1\n        else:\n            right = mid\n    \n    # Check neighbors\n    if left > 0:\n        if abs(arr[left-1] - target) < abs(arr[left] - target):\n            return arr[left-1]\n    \n    return arr[left]\n```\n\n### Advanced Applications\n\n#### Binary Search on Answer\nSometimes we binary search on the solution space:\n\n```python\ndef sqrt_binary_search(n, precision=0.000001):\n    \"\"\"Find square root using binary search\"\"\"\n    if n < 0:\n        return None\n    \n    left, right = 0, n\n    \n    while right - left > precision:\n        mid = (left + right) / 2\n        \n        if mid * mid < n:\n            left = mid\n        else:\n            right = mid\n    \n    return (left + right) / 2\n\ndef can_finish_in_time(tasks, workers, time_limit):\n    \"\"\"Check if tasks can be completed in time\"\"\"\n    # Helper for binary search on answer\n    total_time = 0\n    worker_count = 1\n    \n    for task in tasks:\n        if total_time + task <= time_limit:\n            total_time += task\n        else:\n            worker_count += 1\n            total_time = task\n            if worker_count > workers:\n                return False\n    \n    return True\n\ndef minimum_time_to_complete(tasks, workers):\n    \"\"\"Find minimum time to complete all tasks\"\"\"\n    left = max(tasks)  # Minimum possible time\n    right = sum(tasks)  # Maximum possible time\n    \n    while left < right:\n        mid = (left + right) // 2\n        \n        if can_finish_in_time(tasks, workers, mid):\n            right = mid\n        else:\n            left = mid + 1\n    \n    return left\n```\n\n#### Searching in Rotated Array\n```python\ndef search_rotated_array(arr, target):\n    \"\"\"Search in sorted rotated array\"\"\"\n    left, right = 0, len(arr) - 1\n    \n    while left <= right:\n        mid = (left + right) // 2\n        \n        if arr[mid] == target:\n            return mid\n        \n        # Check which half is sorted\n        if arr[left] <= arr[mid]:  # Left half is sorted\n            if arr[left] <= target < arr[mid]:\n                right = mid - 1\n            else:\n                left = mid + 1\n        else:  # Right half is sorted\n            if arr[mid] < target <= arr[right]:\n                left = mid + 1\n            else:\n                right = mid - 1\n    \n    return -1\n```\n\n### Common Pitfalls and Solutions\n\n#### The Off-By-One Error\n```python\n# WRONG: Infinite loop possible\nwhile left < right:  # Missing equality\n    mid = (left + right) // 2\n    if arr[mid] < target:\n        left = mid  # Should be mid + 1\n\n# CORRECT\nwhile left <= right:  # Include equality\n    mid = (left + right) // 2\n    if arr[mid] < target:\n        left = mid + 1  # Move past mid\n```\n\n#### Integer Overflow (in other languages)\n```python\n# Potentially problematic in languages with integer overflow\nmid = (left + right) // 2\n\n# Safe version\nmid = left + (right - left) // 2\n```\n\n### Real-World Applications\n\n1. **Database Indexes**: B-trees use binary search\n2. **Git Bisect**: Finding which commit introduced a bug\n3. **Load Balancing**: Finding the right server\n4. **Games**: AI decision trees\n5. **Finance**: Option pricing models\n\n### Performance Comparison\n\n```python\nimport time\nimport random\n\ndef performance_test():\n    \"\"\"Compare linear vs binary search\"\"\"\n    sizes = [100, 1000, 10000, 100000, 1000000]\n    \n    for size in sizes:\n        arr = list(range(size))\n        target = random.randint(0, size-1)\n        \n        # Linear search\n        start = time.perf_counter()\n        for _ in range(100):\n            linear_result = linear_search(arr, target)\n        linear_time = time.perf_counter() - start\n        \n        # Binary search\n        start = time.perf_counter()\n        for _ in range(100):\n            binary_result = binary_search_iterative(arr, target)\n        binary_time = time.perf_counter() - start\n        \n        print(f\"Size {size:7}: Linear {linear_time:.4f}s, Binary {binary_time:.4f}s\")\n        print(f\"  Binary is {linear_time/binary_time:.1f}x faster\\n\")\n```\n\n### The Deep Insight\n\nBinary search isn't just an algorithm - it's a problem-solving strategy. Whenever you can:\n1. Order your solution space\n2. Determine if you're too high or too low\n3. Eliminate half the remaining options\n\n...you can apply binary search thinking!\n\n### Practice Challenges\n\n1. Find the peak element in a mountain array\n2. Search in a 2D sorted matrix\n3. Find the smallest letter greater than target\n4. Implement binary search on a linked list\n5. Find the rotation point in a sorted rotated array\n\nRemember: Binary search is about intelligent elimination. Master this concept, and you'll see opportunities to apply it everywhere!",
          "topics": ["Implementation", "Variations", "Binary Search on Answer", "Common Pitfalls", "Advanced Applications"],
          "practice_problems": 12,
          "estimated_time": 45,
          "difficulty": "intermediate",
          "prerequisites": ["arrays", "linear-search"],
          "code_examples": "# Comprehensive binary search implementations\n\n# Standard implementations\ndef binary_search_iterative(arr, target):\n    \"\"\"Classic iterative binary search\"\"\"\n    left, right = 0, len(arr) - 1\n    comparisons = 0\n    \n    while left <= right:\n        comparisons += 1\n        mid = left + (right - left) // 2\n        \n        if arr[mid] == target:\n            print(f\"Found in {comparisons} comparisons\")\n            return mid\n        elif arr[mid] < target:\n            left = mid + 1\n        else:\n            right = mid - 1\n    \n    print(f\"Not found after {comparisons} comparisons\")\n    return -1\n\n# Advanced variations\ndef binary_search_range(arr, target):\n    \"\"\"Find range [first, last] of target\"\"\"\n    def find_first():\n        left, right, result = 0, len(arr) - 1, -1\n        while left <= right:\n            mid = (left + right) // 2\n            if arr[mid] == target:\n                result = mid\n                right = mid - 1\n            elif arr[mid] < target:\n                left = mid + 1\n            else:\n                right = mid - 1\n        return result\n    \n    def find_last():\n        left, right, result = 0, len(arr) - 1, -1\n        while left <= right:\n            mid = (left + right) // 2\n            if arr[mid] == target:\n                result = mid\n                left = mid + 1\n            elif arr[mid] < target:\n                left = mid + 1\n            else:\n                right = mid - 1\n        return result\n    \n    return [find_first(), find_last()]\n\ndef binary_search_floor_ceiling(arr, target):\n    \"\"\"Find floor and ceiling of target\"\"\"\n    n = len(arr)\n    \n    # Find floor (largest element <= target)\n    def find_floor():\n        left, right, floor = 0, n - 1, -1\n        while left <= right:\n            mid = (left + right) // 2\n            if arr[mid] <= target:\n                floor = arr[mid]\n                left = mid + 1\n            else:\n                right = mid - 1\n        return floor\n    \n    # Find ceiling (smallest element >= target)\n    def find_ceiling():\n        left, right, ceiling = 0, n - 1, -1\n        while left <= right:\n            mid = (left + right) // 2\n            if arr[mid] >= target:\n                ceiling = arr[mid]\n                right = mid - 1\n            else:\n                left = mid + 1\n        return ceiling\n    \n    return find_floor(), find_ceiling()\n\n# Binary search on answer\ndef allocate_minimum_pages(books, students):\n    \"\"\"Allocate books to minimize maximum pages per student\"\"\"\n    def is_valid(max_pages):\n        student_count = 1\n        current_pages = 0\n        \n        for pages in books:\n            if current_pages + pages <= max_pages:\n                current_pages += pages\n            else:\n                student_count += 1\n                current_pages = pages\n                if student_count > students:\n                    return False\n        return True\n    \n    if len(books) < students:\n        return -1\n    \n    left = max(books)  # Minimum possible\n    right = sum(books)  # Maximum possible\n    result = -1\n    \n    while left <= right:\n        mid = (left + right) // 2\n        \n        if is_valid(mid):\n            result = mid\n            right = mid - 1\n        else:\n            left = mid + 1\n    \n    return result\n\n# Search in nearly sorted array\ndef search_nearly_sorted(arr, target):\n    \"\"\"Search where elements can be at i-1, i, or i+1\"\"\"\n    left, right = 0, len(arr) - 1\n    \n    while left <= right:\n        mid = (left + right) // 2\n        \n        # Check mid and neighbors\n        if arr[mid] == target:\n            return mid\n        if mid > left and arr[mid-1] == target:\n            return mid - 1\n        if mid < right and arr[mid+1] == target:\n            return mid + 1\n        \n        # Adjust search space\n        if arr[mid] < target:\n            left = mid + 2\n        else:\n            right = mid - 2\n    \n    return -1"
        }
      ]
    },
    {
      "id": "sorting",
      "title": "üìä Sorting Algorithms", 
      "description": "Master the art of ordering data efficiently",
      "lessons": [
        {
          "id": "bubble-sort",
          "title": "Bubble Sort",
          "content": "## Bubble Sort: The Teaching Champion\n\nImagine you're arranging students by height for a class photo. You compare each pair of neighbors and swap them if they're in the wrong order. Keep doing this until everyone is in the right place. That's bubble sort - simple, visual, and perfect for understanding how sorting works.\n\n### Why Study Bubble Sort?\n\nWhile rarely used in production, bubble sort teaches us:\n- How comparison-based sorting works\n- The concept of algorithm stability\n- How to analyze nested loops\n- The importance of optimization\n- When simple solutions are actually fine\n\n### The Visual Intuition\n\nWatch how large values \"bubble up\" to their correct positions:\n\n```\nPass 1: [5,3,8,2,1] ‚Üí [3,5,8,2,1] ‚Üí [3,5,8,2,1] ‚Üí [3,5,2,8,1] ‚Üí [3,5,2,1,8]\n                                                                      ‚Üë 8 bubbled up!\n\nPass 2: [3,5,2,1,8] ‚Üí [3,5,2,1,8] ‚Üí [3,2,5,1,8] ‚Üí [3,2,1,5,8]\n                                                    ‚Üë 5 in place!\n\nPass 3: [3,2,1,5,8] ‚Üí [2,3,1,5,8] ‚Üí [2,1,3,5,8]\n                                      ‚Üë 3 in place!\n\nPass 4: [2,1,3,5,8] ‚Üí [1,2,3,5,8]\n                       ‚Üë Done!\n```\n\n### Basic Implementation\n\n```python\ndef bubble_sort_basic(arr):\n    \"\"\"The simplest bubble sort\"\"\"\n    n = len(arr)\n    \n    for i in range(n):\n        # Last i elements are already in place\n        for j in range(n - 1 - i):\n            # Swap if elements are in wrong order\n            if arr[j] > arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n    \n    return arr\n```\n\n### Optimizations: Making Bubble Sort Smarter\n\n#### Early Termination\nIf no swaps occur in a pass, the array is sorted:\n\n```python\ndef bubble_sort_optimized(arr):\n    \"\"\"Bubble sort with early termination\"\"\"\n    n = len(arr)\n    \n    for i in range(n):\n        swapped = False\n        \n        for j in range(n - 1 - i):\n            if arr[j] > arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n                swapped = True\n        \n        # If no swaps, array is sorted\n        if not swapped:\n            print(f\"Sorted early at pass {i + 1}\")\n            break\n    \n    return arr\n```\n\n#### Cocktail Sort (Bidirectional Bubble Sort)\nBubble in both directions:\n\n```python\ndef cocktail_sort(arr):\n    \"\"\"Bubble sort that goes both ways\"\"\"\n    n = len(arr)\n    start = 0\n    end = n - 1\n    swapped = True\n    \n    while swapped:\n        swapped = False\n        \n        # Bubble left to right\n        for i in range(start, end):\n            if arr[i] > arr[i + 1]:\n                arr[i], arr[i + 1] = arr[i + 1], arr[i]\n                swapped = True\n        \n        if not swapped:\n            break\n        \n        end -= 1\n        swapped = False\n        \n        # Bubble right to left\n        for i in range(end, start, -1):\n            if arr[i] < arr[i - 1]:\n                arr[i], arr[i - 1] = arr[i - 1], arr[i]\n                swapped = True\n        \n        start += 1\n    \n    return arr\n```\n\n### Understanding Stability\n\nBubble sort is **stable** - equal elements maintain their relative order:\n\n```python\nclass Student:\n    def __init__(self, name, grade):\n        self.name = name\n        self.grade = grade\n    \n    def __repr__(self):\n        return f\"{self.name}:{self.grade}\"\n\ndef bubble_sort_stable(students, key=lambda x: x.grade):\n    \"\"\"Stable sort maintaining relative order\"\"\"\n    n = len(students)\n    \n    for i in range(n):\n        for j in range(n - 1 - i):\n            # Use > not >= to maintain stability\n            if key(students[j]) > key(students[j + 1]):\n                students[j], students[j + 1] = students[j + 1], students[j]\n    \n    return students\n\n# Example\nstudents = [\n    Student(\"Alice\", 85),\n    Student(\"Bob\", 90),\n    Student(\"Charlie\", 85),\n    Student(\"David\", 90)\n]\n\nsorted_students = bubble_sort_stable(students)\n# Alice:85 comes before Charlie:85 (original order preserved)\n```\n\n### Performance Analysis\n\n```python\ndef bubble_sort_with_metrics(arr):\n    \"\"\"Bubble sort with performance tracking\"\"\"\n    n = len(arr)\n    comparisons = 0\n    swaps = 0\n    \n    for i in range(n):\n        pass_swaps = 0\n        \n        for j in range(n - 1 - i):\n            comparisons += 1\n            \n            if arr[j] > arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n                swaps += 1\n                pass_swaps += 1\n        \n        print(f\"Pass {i + 1}: {pass_swaps} swaps\")\n        \n        if pass_swaps == 0:\n            break\n    \n    print(f\"\\nTotal comparisons: {comparisons}\")\n    print(f\"Total swaps: {swaps}\")\n    print(f\"Array sorted: {arr}\")\n    \n    return arr\n```\n\n### Time and Space Complexity\n\n**Time Complexity:**\n- Best case: O(n) - already sorted (with optimization)\n- Average case: O(n¬≤) - random order\n- Worst case: O(n¬≤) - reverse sorted\n\n**Space Complexity:** O(1) - sorts in place\n\n### When Bubble Sort Makes Sense\n\n#### Small Datasets\n```python\ndef hybrid_sort(arr):\n    \"\"\"Use bubble sort for small arrays\"\"\"\n    if len(arr) < 10:\n        return bubble_sort_optimized(arr)\n    else:\n        return quick_sort(arr)  # Use faster algorithm\n```\n\n#### Nearly Sorted Data\n```python\ndef sort_nearly_sorted(arr, k):\n    \"\"\"Sort array where elements are at most k positions from target\"\"\"\n    # Bubble sort works well here\n    n = len(arr)\n    \n    for i in range(min(k, n)):\n        swapped = False\n        \n        for j in range(n - 1):\n            if arr[j] > arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n                swapped = True\n        \n        if not swapped:\n            break\n    \n    return arr\n```\n\n#### Educational Visualization\n```python\ndef bubble_sort_visual(arr):\n    \"\"\"Visualize bubble sort step by step\"\"\"\n    n = len(arr)\n    \n    print(\"Initial:\", arr)\n    print(\"-\" * 40)\n    \n    for i in range(n):\n        print(f\"\\nPass {i + 1}:\")\n        swapped = False\n        \n        for j in range(n - 1 - i):\n            # Show comparison\n            print(f\"  Compare {arr[j]} and {arr[j+1]}\", end=\"\")\n            \n            if arr[j] > arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n                print(f\" ‚Üí Swap! New: {arr}\")\n                swapped = True\n            else:\n                print(\" ‚Üí No swap\")\n        \n        if not swapped:\n            print(\"  Array is sorted!\")\n            break\n    \n    print(\"\\nFinal:\", arr)\n    return arr\n```\n\n### Bubble Sort Variations\n\n#### Recursive Bubble Sort\n```python\ndef bubble_sort_recursive(arr, n=None):\n    \"\"\"Recursive implementation\"\"\"\n    if n is None:\n        n = len(arr)\n    \n    # Base case\n    if n == 1:\n        return arr\n    \n    # One pass of bubble sort\n    swapped = False\n    for i in range(n - 1):\n        if arr[i] > arr[i + 1]:\n            arr[i], arr[i + 1] = arr[i + 1], arr[i]\n            swapped = True\n    \n    # If no swaps, array is sorted\n    if not swapped:\n        return arr\n    \n    # Recur for remaining elements\n    return bubble_sort_recursive(arr, n - 1)\n```\n\n#### Odd-Even Sort (Parallel Bubble Sort)\n```python\ndef odd_even_sort(arr):\n    \"\"\"Bubble sort variant for parallel processing\"\"\"\n    n = len(arr)\n    sorted_flag = False\n    \n    while not sorted_flag:\n        sorted_flag = True\n        \n        # Odd indexed pairs\n        for i in range(1, n - 1, 2):\n            if arr[i] > arr[i + 1]:\n                arr[i], arr[i + 1] = arr[i + 1], arr[i]\n                sorted_flag = False\n        \n        # Even indexed pairs\n        for i in range(0, n - 1, 2):\n            if arr[i] > arr[i + 1]:\n                arr[i], arr[i + 1] = arr[i + 1], arr[i]\n                sorted_flag = False\n    \n    return arr\n```\n\n### Real-World Applications\n\n1. **Teaching Tool**: Perfect for demonstrating sorting concepts\n2. **Small Embedded Systems**: Simple implementation, minimal code\n3. **Nearly Sorted Detection**: Efficiently handles almost-sorted data\n4. **Stability Requirements**: When maintaining relative order matters\n5. **Hybrid Algorithms**: Base case for small subarrays in quicksort\n\n### The Key Insight\n\nBubble sort teaches us that:\n1. Simple algorithms can be perfect for specific situations\n2. Optimization matters even in \"bad\" algorithms\n3. Understanding the basics helps us appreciate advanced techniques\n4. Not every problem needs the most sophisticated solution\n\n### Practice Exercises\n\n1. Implement bubble sort for a linked list\n2. Sort strings by length using bubble sort\n3. Count inversions while bubble sorting\n4. Implement a three-way bubble sort for arrays with many duplicates\n5. Create a bubble sort that tracks the history of all swaps\n\nRemember: Bubble sort might not win any speed contests, but it wins the clarity contest every time!",
          "topics": ["Basic Algorithm", "Optimizations", "Stability", "Complexity Analysis", "Variations"],
          "practice_problems": 8,
          "estimated_time": 30,
          "difficulty": "beginner",
          "prerequisites": ["arrays", "big-o"],
          "code_examples": "# Complete bubble sort implementations\n\n# All variations with detailed comments\ndef bubble_sort_comprehensive(arr, debug=False):\n    \"\"\"Comprehensive bubble sort with all optimizations\"\"\"\n    n = len(arr)\n    total_comparisons = 0\n    total_swaps = 0\n    \n    for i in range(n):\n        # Track if any swaps occur\n        swapped = False\n        pass_comparisons = 0\n        pass_swaps = 0\n        \n        # Last i elements are already sorted\n        for j in range(n - 1 - i):\n            total_comparisons += 1\n            pass_comparisons += 1\n            \n            if arr[j] > arr[j + 1]:\n                # Perform swap\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n                total_swaps += 1\n                pass_swaps += 1\n                swapped = True\n                \n                if debug:\n                    print(f\"  Swap: {arr[j+1]} ‚Üî {arr[j]}\")\n        \n        if debug:\n            print(f\"Pass {i+1}: {pass_comparisons} comparisons, {pass_swaps} swaps\")\n            print(f\"  Array: {arr}\")\n        \n        # Early termination if sorted\n        if not swapped:\n            if debug:\n                print(f\"Sorted early after {i+1} passes!\")\n            break\n    \n    if debug:\n        print(f\"\\nFinal Statistics:\")\n        print(f\"  Total Comparisons: {total_comparisons}\")\n        print(f\"  Total Swaps: {total_swaps}\")\n        print(f\"  Sorted Array: {arr}\")\n    \n    return arr\n\n# Bubble sort for custom objects\ndef bubble_sort_objects(objects, key_func):\n    \"\"\"Sort objects using custom key function\"\"\"\n    n = len(objects)\n    \n    for i in range(n):\n        swapped = False\n        \n        for j in range(n - 1 - i):\n            if key_func(objects[j]) > key_func(objects[j + 1]):\n                objects[j], objects[j + 1] = objects[j + 1], objects[j]\n                swapped = True\n        \n        if not swapped:\n            break\n    \n    return objects\n\n# Example usage with custom objects\nclass Task:\n    def __init__(self, name, priority, duration):\n        self.name = name\n        self.priority = priority\n        self.duration = duration\n    \n    def __repr__(self):\n        return f\"Task({self.name}, p:{self.priority}, d:{self.duration})\"\n\ntasks = [\n    Task(\"Email\", 2, 10),\n    Task(\"Meeting\", 1, 60),\n    Task(\"Code\", 1, 120),\n    Task(\"Lunch\", 3, 30)\n]\n\n# Sort by priority, then duration\nsorted_tasks = bubble_sort_objects(\n    tasks,\n    key_func=lambda t: (t.priority, t.duration)\n)\n\n# Advanced bubble sort with multiple criteria\ndef multi_criteria_bubble_sort(arr, criteria):\n    \"\"\"Sort using multiple criteria\"\"\"\n    n = len(arr)\n    \n    for criterion in reversed(criteria):\n        for i in range(n):\n            swapped = False\n            \n            for j in range(n - 1 - i):\n                if criterion(arr[j]) > criterion(arr[j + 1]):\n                    arr[j], arr[j + 1] = arr[j + 1], arr[j]\n                    swapped = True\n            \n            if not swapped:\n                break\n    \n    return arr"
        },
        {
          "id": "quicksort",
          "title": "QuickSort",
          "content": "## QuickSort: The Divide-and-Conquer Master\n\nImagine organizing a huge pile of exams by score. You pick a random exam (say, 75%), then put all lower scores to the left and higher scores to the right. Now you have two smaller piles to sort. Repeat this process for each pile, and soon everything is perfectly ordered. That's QuickSort - elegant, fast, and surprisingly simple!\n\n### The Genius of QuickSort\n\nQuickSort embodies the divide-and-conquer strategy:\n1. **Divide**: Choose a pivot and partition around it\n2. **Conquer**: Recursively sort the subarrays\n3. **Combine**: Nothing to do - already sorted!\n\nIt's like organizing a bookshelf by repeatedly picking a book and arranging others relative to it.\n\n### Core Implementation\n\n```python\ndef quicksort(arr, low=0, high=None):\n    \"\"\"Classic QuickSort implementation\"\"\"\n    if high is None:\n        high = len(arr) - 1\n    \n    if low < high:\n        # Partition and get pivot index\n        pivot_index = partition(arr, low, high)\n        \n        # Recursively sort left and right subarrays\n        quicksort(arr, low, pivot_index - 1)\n        quicksort(arr, pivot_index + 1, high)\n    \n    return arr\n\ndef partition(arr, low, high):\n    \"\"\"Lomuto partition scheme\"\"\"\n    # Choose rightmost element as pivot\n    pivot = arr[high]\n    \n    # Index of smaller element\n    i = low - 1\n    \n    for j in range(low, high):\n        # If current element is smaller than pivot\n        if arr[j] <= pivot:\n            i += 1\n            arr[i], arr[j] = arr[j], arr[i]\n    \n    # Place pivot in its correct position\n    arr[i + 1], arr[high] = arr[high], arr[i + 1]\n    return i + 1\n```\n\n### Partition Schemes Explained\n\n#### Lomuto Partition (Simple but Clear)\n```python\ndef lomuto_partition(arr, low, high):\n    \"\"\"Easy to understand partition\"\"\"\n    pivot = arr[high]\n    i = low - 1  # Index of smaller element\n    \n    for j in range(low, high):\n        if arr[j] <= pivot:\n            i += 1\n            arr[i], arr[j] = arr[j], arr[i]\n    \n    arr[i + 1], arr[high] = arr[high], arr[i + 1]\n    return i + 1\n```\n\n#### Hoare Partition (More Efficient)\n```python\ndef hoare_partition(arr, low, high):\n    \"\"\"Original and more efficient partition\"\"\"\n    pivot = arr[low]\n    i = low - 1\n    j = high + 1\n    \n    while True:\n        # Move i right until element >= pivot\n        i += 1\n        while arr[i] < pivot:\n            i += 1\n        \n        # Move j left until element <= pivot\n        j -= 1\n        while arr[j] > pivot:\n            j -= 1\n        \n        # If pointers crossed, partitioning is done\n        if i >= j:\n            return j\n        \n        # Swap elements\n        arr[i], arr[j] = arr[j], arr[i]\n```\n\n### Pivot Selection Strategies\n\nThe choice of pivot dramatically affects performance:\n\n```python\nimport random\n\ndef quicksort_random_pivot(arr, low=0, high=None):\n    \"\"\"QuickSort with random pivot\"\"\"\n    if high is None:\n        high = len(arr) - 1\n    \n    if low < high:\n        # Choose random pivot\n        random_index = random.randint(low, high)\n        arr[random_index], arr[high] = arr[high], arr[random_index]\n        \n        pivot_index = partition(arr, low, high)\n        quicksort_random_pivot(arr, low, pivot_index - 1)\n        quicksort_random_pivot(arr, pivot_index + 1, high)\n    \n    return arr\n\ndef median_of_three(arr, low, high):\n    \"\"\"Choose median of first, middle, and last\"\"\"\n    mid = (low + high) // 2\n    \n    # Sort three elements\n    if arr[low] > arr[mid]:\n        arr[low], arr[mid] = arr[mid], arr[low]\n    if arr[mid] > arr[high]:\n        arr[mid], arr[high] = arr[high], arr[mid]\n    if arr[low] > arr[mid]:\n        arr[low], arr[mid] = arr[mid], arr[low]\n    \n    # Use middle as pivot\n    return mid\n\ndef quicksort_median_of_three(arr, low=0, high=None):\n    \"\"\"QuickSort with median-of-three pivot\"\"\"\n    if high is None:\n        high = len(arr) - 1\n    \n    if low < high:\n        # Choose median of three as pivot\n        pivot_index = median_of_three(arr, low, high)\n        arr[pivot_index], arr[high] = arr[high], arr[pivot_index]\n        \n        pivot_index = partition(arr, low, high)\n        quicksort_median_of_three(arr, low, pivot_index - 1)\n        quicksort_median_of_three(arr, pivot_index + 1, high)\n    \n    return arr\n```\n\n### Three-Way QuickSort (Dutch National Flag)\n\nHandles duplicates efficiently:\n\n```python\ndef quicksort_3way(arr, low=0, high=None):\n    \"\"\"Three-way QuickSort for arrays with duplicates\"\"\"\n    if high is None:\n        high = len(arr) - 1\n    \n    if low < high:\n        lt, gt = partition_3way(arr, low, high)\n        quicksort_3way(arr, low, lt - 1)\n        quicksort_3way(arr, gt + 1, high)\n    \n    return arr\n\ndef partition_3way(arr, low, high):\n    \"\"\"Three-way partition: < = > pivot\"\"\"\n    pivot = arr[low]\n    i = low\n    lt = low\n    gt = high\n    \n    while i <= gt:\n        if arr[i] < pivot:\n            arr[lt], arr[i] = arr[i], arr[lt]\n            lt += 1\n            i += 1\n        elif arr[i] > pivot:\n            arr[i], arr[gt] = arr[gt], arr[i]\n            gt -= 1\n        else:\n            i += 1\n    \n    return lt, gt\n```\n\n### Iterative QuickSort\n\nAvoid recursion stack overflow:\n\n```python\ndef quicksort_iterative(arr):\n    \"\"\"Iterative QuickSort using explicit stack\"\"\"\n    if len(arr) <= 1:\n        return arr\n    \n    stack = [(0, len(arr) - 1)]\n    \n    while stack:\n        low, high = stack.pop()\n        \n        if low < high:\n            pivot_index = partition(arr, low, high)\n            \n            # Push subarrays to stack\n            # Push larger subarray first for optimization\n            if pivot_index - low < high - pivot_index:\n                stack.append((pivot_index + 1, high))\n                stack.append((low, pivot_index - 1))\n            else:\n                stack.append((low, pivot_index - 1))\n                stack.append((pivot_index + 1, high))\n    \n    return arr\n```\n\n### Hybrid QuickSort\n\nCombine with insertion sort for small subarrays:\n\n```python\ndef insertion_sort(arr, low, high):\n    \"\"\"Insertion sort for small arrays\"\"\"\n    for i in range(low + 1, high + 1):\n        key = arr[i]\n        j = i - 1\n        while j >= low and arr[j] > key:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key\n\ndef quicksort_hybrid(arr, low=0, high=None, threshold=10):\n    \"\"\"Hybrid QuickSort with insertion sort for small arrays\"\"\"\n    if high is None:\n        high = len(arr) - 1\n    \n    if low < high:\n        # Use insertion sort for small subarrays\n        if high - low <= threshold:\n            insertion_sort(arr, low, high)\n        else:\n            pivot_index = partition(arr, low, high)\n            quicksort_hybrid(arr, low, pivot_index - 1, threshold)\n            quicksort_hybrid(arr, pivot_index + 1, high, threshold)\n    \n    return arr\n```\n\n### Performance Analysis\n\n```python\nimport time\nimport random\n\ndef analyze_quicksort_performance():\n    \"\"\"Compare different QuickSort variants\"\"\"\n    sizes = [100, 1000, 10000]\n    \n    for size in sizes:\n        print(f\"\\nArray size: {size}\")\n        \n        # Random array\n        arr_random = [random.randint(1, 1000) for _ in range(size)]\n        \n        # Already sorted (worst case for basic QuickSort)\n        arr_sorted = list(range(size))\n        \n        # Many duplicates\n        arr_duplicates = [random.randint(1, 10) for _ in range(size)]\n        \n        variants = [\n            (\"Basic QuickSort\", quicksort),\n            (\"Random Pivot\", quicksort_random_pivot),\n            (\"Median of Three\", quicksort_median_of_three),\n            (\"Three-Way\", quicksort_3way),\n            (\"Hybrid\", quicksort_hybrid)\n        ]\n        \n        for name, func in variants:\n            # Test on random array\n            arr_copy = arr_random.copy()\n            start = time.perf_counter()\n            func(arr_copy)\n            elapsed = time.perf_counter() - start\n            print(f\"  {name:20} Random: {elapsed:.4f}s\")\n```\n\n### Complexity Analysis\n\n**Time Complexity:**\n- Best case: O(n log n) - balanced partitions\n- Average case: O(n log n) - random data\n- Worst case: O(n¬≤) - already sorted (poor pivot choice)\n\n**Space Complexity:**\n- O(log n) - recursion stack (average)\n- O(n) - recursion stack (worst case)\n\n### QuickSort vs Other Algorithms\n\n```python\ndef compare_sorting_algorithms(arr):\n    \"\"\"Compare QuickSort with other algorithms\"\"\"\n    import heapq\n    \n    n = len(arr)\n    \n    # QuickSort: O(n log n) average, in-place\n    # Best for: General purpose, average case performance\n    \n    # MergeSort: O(n log n) always, stable, O(n) space\n    # Best for: Guaranteed performance, stability needed\n    \n    # HeapSort: O(n log n) always, in-place\n    # Best for: Memory constraints, worst-case guarantee\n    \n    # When to use QuickSort:\n    # 1. Average case performance matters most\n    # 2. In-place sorting needed\n    # 3. Cache performance important (good locality)\n    # 4. Random data expected\n    \n    # When to avoid QuickSort:\n    # 1. Worst-case guarantee needed\n    # 2. Stability required\n    # 3. Data might be already sorted\n    # 4. Dealing with linked lists\n```\n\n### Real-World Applications\n\n1. **Language Libraries**: C++ std::sort, Java Arrays.sort (for primitives)\n2. **Database Systems**: Query result sorting\n3. **File Systems**: Directory listing\n4. **Search Engines**: Result ranking\n5. **Data Analytics**: Statistical computations\n\n### Advanced QuickSort: Introspective Sort\n\n```python\ndef introsort(arr):\n    \"\"\"Introspective sort - QuickSort + HeapSort hybrid\"\"\"\n    max_depth = 2 * math.log2(len(arr))\n    return introsort_helper(arr, 0, len(arr) - 1, max_depth)\n\ndef introsort_helper(arr, low, high, max_depth):\n    if low < high:\n        if max_depth == 0:\n            # Switch to heapsort for deep recursion\n            heapsort_range(arr, low, high)\n        else:\n            pivot = partition(arr, low, high)\n            introsort_helper(arr, low, pivot - 1, max_depth - 1)\n            introsort_helper(arr, pivot + 1, high, max_depth - 1)\n    return arr\n```\n\n### The Deep Insight\n\nQuickSort teaches us that:\n1. **Good average case often beats guaranteed worst case**\n2. **Divide-and-conquer is incredibly powerful**\n3. **Small optimizations (pivot selection) matter greatly**\n4. **Hybrid approaches often win in practice**\n\n### Practice Challenges\n\n1. Implement QuickSort for linked lists\n2. Find the kth smallest element using QuickSort partition\n3. Sort an array of 0s, 1s, and 2s in one pass\n4. Implement dual-pivot QuickSort\n5. Create a stable version of QuickSort\n\nRemember: QuickSort isn't just an algorithm - it's a masterclass in algorithmic thinking!",
          "topics": ["Partitioning", "Pivot Selection", "Three-way QuickSort", "Complexity Analysis", "Optimizations"],
          "practice_problems": 15,
          "estimated_time": 60,
          "difficulty": "intermediate",
          "prerequisites": ["arrays", "recursion", "bubble-sort"],
          "code_examples": "# Complete QuickSort implementation suite\n\nimport random\nimport math\n\n# Standard QuickSort implementations\ndef quicksort_complete(arr, low=0, high=None, stats=None):\n    \"\"\"Complete QuickSort with statistics tracking\"\"\"\n    if stats is None:\n        stats = {'comparisons': 0, 'swaps': 0, 'recursions': 0}\n    \n    if high is None:\n        high = len(arr) - 1\n    \n    if low < high:\n        stats['recursions'] += 1\n        pivot_index = partition_with_stats(arr, low, high, stats)\n        quicksort_complete(arr, low, pivot_index - 1, stats)\n        quicksort_complete(arr, pivot_index + 1, high, stats)\n    \n    return arr, stats\n\ndef partition_with_stats(arr, low, high, stats):\n    \"\"\"Partition with performance tracking\"\"\"\n    pivot = arr[high]\n    i = low - 1\n    \n    for j in range(low, high):\n        stats['comparisons'] += 1\n        if arr[j] <= pivot:\n            i += 1\n            arr[i], arr[j] = arr[j], arr[i]\n            stats['swaps'] += 1\n    \n    arr[i + 1], arr[high] = arr[high], arr[i + 1]\n    stats['swaps'] += 1\n    return i + 1\n\n# QuickSelect for finding kth element\ndef quickselect(arr, k, low=0, high=None):\n    \"\"\"Find kth smallest element in O(n) average time\"\"\"\n    if high is None:\n        high = len(arr) - 1\n    \n    if low == high:\n        return arr[low]\n    \n    pivot_index = partition(arr, low, high)\n    \n    if k == pivot_index:\n        return arr[k]\n    elif k < pivot_index:\n        return quickselect(arr, k, low, pivot_index - 1)\n    else:\n        return quickselect(arr, k, pivot_index + 1, high)\n\n# Dual-pivot QuickSort\ndef dual_pivot_quicksort(arr, low=0, high=None):\n    \"\"\"QuickSort with two pivots\"\"\"\n    if high is None:\n        high = len(arr) - 1\n    \n    if low < high:\n        lp, rp = dual_pivot_partition(arr, low, high)\n        dual_pivot_quicksort(arr, low, lp - 1)\n        dual_pivot_quicksort(arr, lp + 1, rp - 1)\n        dual_pivot_quicksort(arr, rp + 1, high)\n    \n    return arr\n\ndef dual_pivot_partition(arr, low, high):\n    \"\"\"Partition using two pivots\"\"\"\n    if arr[low] > arr[high]:\n        arr[low], arr[high] = arr[high], arr[low]\n    \n    pivot1, pivot2 = arr[low], arr[high]\n    i = low + 1\n    k = low + 1\n    j = high - 1\n    \n    while k <= j:\n        if arr[k] < pivot1:\n            arr[i], arr[k] = arr[k], arr[i]\n            i += 1\n            k += 1\n        elif arr[k] > pivot2:\n            arr[k], arr[j] = arr[j], arr[k]\n            j -= 1\n        else:\n            k += 1\n    \n    arr[low], arr[i - 1] = arr[i - 1], arr[low]\n    arr[high], arr[j + 1] = arr[j + 1], arr[high]\n    \n    return i - 1, j + 1\n\n# Stable QuickSort\ndef stable_quicksort(arr):\n    \"\"\"Stable version of QuickSort\"\"\"\n    if len(arr) <= 1:\n        return arr\n    \n    pivot = arr[len(arr) // 2]\n    less = [x for x in arr if x < pivot]\n    equal = [x for x in arr if x == pivot]\n    greater = [x for x in arr if x > pivot]\n    \n    return stable_quicksort(less) + equal + stable_quicksort(greater)"
        }
      ]
    },
    {
      "id": "data-structures",
      "title": "üèóÔ∏è Data Structures",
      "description": "Essential data organization techniques",
      "lessons": [
        {
          "id": "linked-lists",
          "title": "Linked Lists",
          "content": "## Linked Lists: The Dynamic Chain\n\nImagine a treasure hunt where each clue tells you where to find the next one. That's a linked list - a chain of nodes where each node points to the next. Unlike arrays that need continuous memory, linked lists can be scattered anywhere in memory, connected only by pointers.\n\n### Why Linked Lists Matter\n\nLinked lists solve fundamental problems:\n- Dynamic size without reallocation\n- Efficient insertion and deletion at any position\n- Foundation for stacks, queues, and graphs\n- Memory efficiency for sparse data\n\n### Complete implementation and detailed content continues...",
          "topics": ["Node Structure", "Types of Linked Lists", "Operations", "Memory Management", "Applications"],
          "practice_problems": 12,
          "estimated_time": 45,
          "difficulty": "intermediate",
          "prerequisites": ["arrays", "pointers"],
          "code_examples": "# Full linked list implementation with all operations..."
        },
        {
          "id": "stacks",
          "title": "Stacks",
          "content": "## Stacks: Last In, First Out\n\nThink of a stack of plates - you can only take the top plate and can only add new plates on top. This Last-In-First-Out (LIFO) principle makes stacks perfect for tracking history, managing function calls, and parsing expressions.\n\n### Complete detailed content about stacks...",
          "topics": ["LIFO Principle", "Implementation", "Applications", "Stack vs Recursion", "Common Patterns"],
          "practice_problems": 10,
          "estimated_time": 35,
          "difficulty": "beginner",
          "prerequisites": ["arrays"],
          "code_examples": "# Complete stack implementation..."
        },
        {
          "id": "queues",
          "title": "Queues",
          "content": "## Queues: First In, First Out\n\nA queue is like a line at a coffee shop - first person in line gets served first. This First-In-First-Out (FIFO) principle makes queues essential for task scheduling, breadth-first search, and managing resources fairly.\n\n### Complete detailed content about queues...",
          "topics": ["FIFO Principle", "Circular Queues", "Priority Queues", "Deques", "Applications"],
          "practice_problems": 10,
          "estimated_time": 35,
          "difficulty": "beginner",
          "prerequisites": ["arrays"],
          "code_examples": "# Complete queue implementation..."
        }
      ]
    },
    {
      "id": "trees",
      "title": "üå≥ Trees & Graphs",
      "description": "Hierarchical and networked data structures",
      "lessons": [
        {
          "id": "binary-trees",
          "title": "Binary Trees",
          "content": "## Binary Trees: The Hierarchical Foundation\n\nA binary tree is like a family tree where each person has at most two children. This simple constraint creates a powerful structure for organizing hierarchical data, enabling efficient searching, sorting, and decision-making.\n\n### Complete detailed content about binary trees...",
          "topics": ["Tree Terminology", "Traversals", "Binary Search Trees", "Balanced Trees", "Applications"],
          "practice_problems": 15,
          "estimated_time": 60,
          "difficulty": "intermediate",
          "prerequisites": ["linked-lists", "recursion"],
          "code_examples": "# Complete binary tree implementation..."
        },
        {
          "id": "graphs",
          "title": "Graphs",
          "content": "## Graphs: Networks and Connections\n\nGraphs model relationships - social networks, road maps, dependencies. They're the most flexible data structure, representing any kind of connection between objects.\n\n### Complete detailed content about graphs...",
          "topics": ["Graph Types", "Representations", "Traversals", "Shortest Paths", "Applications"],
          "practice_problems": 18,
          "estimated_time": 75,
          "difficulty": "advanced",
          "prerequisites": ["trees", "queues"],
          "code_examples": "# Complete graph implementation..."
        }
      ]
    },
    {
      "id": "advanced",
      "title": "üöÄ Advanced Topics",
      "description": "Complex algorithms and optimization techniques",
      "lessons": [
        {
          "id": "dynamic-programming",
          "title": "Dynamic Programming",
          "content": "## Dynamic Programming: Smart Recursion\n\nDynamic programming is like assembling a jigsaw puzzle - you solve small pieces first, then combine them to solve bigger pieces. By remembering solutions to subproblems, we avoid redundant calculations.\n\n### Complete detailed content about dynamic programming...",
          "topics": ["Memoization", "Tabulation", "Classic Problems", "Optimization", "State Machines"],
          "practice_problems": 20,
          "estimated_time": 90,
          "difficulty": "advanced",
          "prerequisites": ["recursion", "arrays"],
          "code_examples": "# Complete DP examples..."
        },
        {
          "id": "greedy-algorithms",
          "title": "Greedy Algorithms",
          "content": "## Greedy Algorithms: Local Optimization\n\nGreedy algorithms make the best choice at each step, hoping to find the global optimum. Like picking the largest denomination bills first when making change.\n\n### Complete detailed content about greedy algorithms...",
          "topics": ["Greedy Choice Property", "Classic Problems", "Proof Techniques", "When Greedy Works", "Applications"],
          "practice_problems": 15,
          "estimated_time": 60,
          "difficulty": "intermediate",
          "prerequisites": ["sorting", "graphs"],
          "code_examples": "# Complete greedy algorithm examples..."
        }
      ]
    }
  ]
}