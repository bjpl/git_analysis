import { renderHook, waitFor, act } from '@testing-library/react';\nimport { vi, describe, it, expect, beforeEach } from 'vitest';\nimport { QueryClient, QueryClientProvider } from '@tanstack/react-query';\nimport { useAIGeneration } from '../../../src/hooks/useAIGeneration';\nimport { mockAIDescriptionResponse } from '../../mocks/mockData';\n\n// Mock OpenAI service\nconst mockOpenAI = {\n  chat: {\n    completions: {\n      create: vi.fn(),\n    },\n  },\n};\n\nvi.mock('../../../src/services/openaiService', () => ({\n  openaiService: mockOpenAI,\n}));\n\nconst createWrapper = () => {\n  const queryClient = new QueryClient({\n    defaultOptions: {\n      queries: { retry: false },\n      mutations: { retry: false },\n    },\n  });\n\n  return ({ children }: { children: React.ReactNode }) => (\n    <QueryClientProvider client={queryClient}>\n      {children}\n    </QueryClientProvider>\n  );\n};\n\ndescribe('useAIGeneration', () => {\n  beforeEach(() => {\n    vi.clearAllMocks();\n  });\n\n  it('should generate description successfully', async () => {\n    const mockResponse = mockAIDescriptionResponse('beach scene');\n    mockOpenAI.chat.completions.create.mockResolvedValue(mockResponse);\n\n    const { result } = renderHook(() => useAIGeneration(), {\n      wrapper: createWrapper(),\n    });\n\n    expect(result.current.isGenerating).toBe(false);\n    expect(result.current.error).toBeNull();\n\n    await act(async () => {\n      const description = await result.current.generateDescription({\n        imageUrl: 'https://example.com/beach.jpg',\n        prompt: 'Describe this beach scene in Spanish',\n        style: 'academic',\n        vocabularyLevel: 'intermediate',\n      });\n\n      expect(description).toBeDefined();\n      expect(typeof description).toBe('string');\n    });\n\n    expect(mockOpenAI.chat.completions.create).toHaveBeenCalledWith(\n      expect.objectContaining({\n        model: expect.any(String),\n        messages: expect.arrayContaining([\n          expect.objectContaining({\n            role: 'user',\n            content: expect.arrayContaining([\n              expect.objectContaining({ type: 'text' }),\n              expect.objectContaining({ type: 'image_url' }),\n            ]),\n          }),\n        ]),\n      })\n    );\n  });\n\n  it('should handle generation errors', async () => {\n    const mockError = new Error('OpenAI API Error');\n    mockOpenAI.chat.completions.create.mockRejectedValue(mockError);\n\n    const { result } = renderHook(() => useAIGeneration(), {\n      wrapper: createWrapper(),\n    });\n\n    await act(async () => {\n      try {\n        await result.current.generateDescription({\n          imageUrl: 'https://example.com/beach.jpg',\n          prompt: 'Describe this image',\n        });\n      } catch (error) {\n        expect(error).toBe(mockError);\n      }\n    });\n\n    expect(result.current.error).toBe(mockError);\n  });\n\n  it('should generate vocabulary from text', async () => {\n    const mockVocabResponse = {\n      ...mockAIDescriptionResponse(''),\n      choices: [{\n        index: 0,\n        message: {\n          role: 'assistant',\n          content: JSON.stringify({\n            \"Sustantivos\": [\"la playa\", \"el mar\", \"la arena\"],\n            \"Verbos\": [\"caminar\", \"nadar\", \"relajarse\"],\n            \"Adjetivos\": [\"hermosa\", \"tranquila\", \"azul\"],\n            \"Frases clave\": [\"día soleado\", \"agua cristalina\"]\n          })\n        },\n        finish_reason: 'stop',\n      }],\n    };\n\n    mockOpenAI.chat.completions.create.mockResolvedValue(mockVocabResponse);\n\n    const { result } = renderHook(() => useAIGeneration(), {\n      wrapper: createWrapper(),\n    });\n\n    await act(async () => {\n      const vocabulary = await result.current.extractVocabulary(\n        'Una playa hermosa con arena blanca y mar azul'\n      );\n\n      expect(vocabulary).toBeDefined();\n      expect(vocabulary.Sustantivos).toContain('la playa');\n      expect(vocabulary.Verbos).toContain('caminar');\n      expect(vocabulary.Adjetivos).toContain('hermosa');\n    });\n\n    expect(mockOpenAI.chat.completions.create).toHaveBeenCalledWith(\n      expect.objectContaining({\n        response_format: { type: 'json_object' },\n      })\n    );\n  });\n\n  it('should handle streaming responses', async () => {\n    const mockStream = {\n      [Symbol.asyncIterator]: async function* () {\n        yield { choices: [{ delta: { content: 'Una ' } }] };\n        yield { choices: [{ delta: { content: 'playa ' } }] };\n        yield { choices: [{ delta: { content: 'hermosa' } }] };\n      },\n    };\n\n    mockOpenAI.chat.completions.create.mockResolvedValue(mockStream);\n\n    const { result } = renderHook(() => useAIGeneration(), {\n      wrapper: createWrapper(),\n    });\n\n    const chunks: string[] = [];\n    const onChunk = (chunk: string) => chunks.push(chunk);\n\n    await act(async () => {\n      await result.current.generateDescriptionStream({\n        imageUrl: 'https://example.com/beach.jpg',\n        prompt: 'Describe this image',\n        onChunk,\n      });\n    });\n\n    expect(chunks).toEqual(['Una ', 'playa ', 'hermosa']);\n  });\n\n  it('should validate image URL format', async () => {\n    const { result } = renderHook(() => useAIGeneration(), {\n      wrapper: createWrapper(),\n    });\n\n    await act(async () => {\n      try {\n        await result.current.generateDescription({\n          imageUrl: 'invalid-url',\n          prompt: 'Describe this image',\n        });\n      } catch (error) {\n        expect(error).toBeInstanceOf(Error);\n        expect(error.message).toContain('Invalid image URL');\n      }\n    });\n  });\n\n  it('should handle rate limiting', async () => {\n    const rateLimitError = new Error('Rate limit exceeded');\n    // @ts-ignore\n    rateLimitError.status = 429;\n    \n    mockOpenAI.chat.completions.create.mockRejectedValue(rateLimitError);\n\n    const { result } = renderHook(() => useAIGeneration(), {\n      wrapper: createWrapper(),\n    });\n\n    await act(async () => {\n      try {\n        await result.current.generateDescription({\n          imageUrl: 'https://example.com/beach.jpg',\n          prompt: 'Describe this image',\n        });\n      } catch (error) {\n        expect(error).toBe(rateLimitError);\n      }\n    });\n\n    expect(result.current.error).toBe(rateLimitError);\n  });\n\n  it('should generate translation', async () => {\n    const mockTranslationResponse = {\n      ...mockAIDescriptionResponse(''),\n      choices: [{\n        index: 0,\n        message: {\n          role: 'assistant',\n          content: 'beach'\n        },\n        finish_reason: 'stop',\n      }],\n    };\n\n    mockOpenAI.chat.completions.create.mockResolvedValue(mockTranslationResponse);\n\n    const { result } = renderHook(() => useAIGeneration(), {\n      wrapper: createWrapper(),\n    });\n\n    await act(async () => {\n      const translation = await result.current.translateText({\n        text: 'playa',\n        targetLanguage: 'en',\n        context: 'Una playa hermosa',\n      });\n\n      expect(translation).toBe('beach');\n    });\n\n    expect(mockOpenAI.chat.completions.create).toHaveBeenCalledWith(\n      expect.objectContaining({\n        messages: expect.arrayContaining([\n          expect.objectContaining({\n            role: 'user',\n            content: expect.stringContaining('playa'),\n          }),\n        ]),\n      })\n    );\n  });\n\n  it('should generate quiz questions', async () => {\n    const mockQuizResponse = {\n      ...mockAIDescriptionResponse(''),\n      choices: [{\n        index: 0,\n        message: {\n          role: 'assistant',\n          content: JSON.stringify({\n            questions: [\n              {\n                type: 'multiple-choice',\n                question: '¿Qué significa \"playa\"?',\n                options: ['beach', 'mountain', 'forest', 'city'],\n                correct: 0,\n                explanation: 'Playa means beach in Spanish'\n              },\n              {\n                type: 'fill-in-blank',\n                question: 'Voy a la _____ para nadar',\n                answer: 'playa',\n                explanation: 'We go to the beach to swim'\n              }\n            ]\n          })\n        },\n        finish_reason: 'stop',\n      }],\n    };\n\n    mockOpenAI.chat.completions.create.mockResolvedValue(mockQuizResponse);\n\n    const { result } = renderHook(() => useAIGeneration(), {\n      wrapper: createWrapper(),\n    });\n\n    await act(async () => {\n      const quiz = await result.current.generateQuiz({\n        vocabulary: ['playa', 'montaña', 'bosque'],\n        difficulty: 'intermediate',\n        questionCount: 2,\n      });\n\n      expect(quiz.questions).toHaveLength(2);\n      expect(quiz.questions[0].type).toBe('multiple-choice');\n      expect(quiz.questions[1].type).toBe('fill-in-blank');\n    });\n  });\n\n  it('should cancel ongoing generation', async () => {\n    // Mock a long-running request\n    const mockPromise = new Promise((resolve) => {\n      setTimeout(() => resolve(mockAIDescriptionResponse('test')), 5000);\n    });\n    \n    mockOpenAI.chat.completions.create.mockReturnValue(mockPromise);\n\n    const { result } = renderHook(() => useAIGeneration(), {\n      wrapper: createWrapper(),\n    });\n\n    act(() => {\n      result.current.generateDescription({\n        imageUrl: 'https://example.com/beach.jpg',\n        prompt: 'Describe this image',\n      });\n    });\n\n    expect(result.current.isGenerating).toBe(true);\n\n    act(() => {\n      result.current.cancelGeneration();\n    });\n\n    expect(result.current.isGenerating).toBe(false);\n  });\n});"